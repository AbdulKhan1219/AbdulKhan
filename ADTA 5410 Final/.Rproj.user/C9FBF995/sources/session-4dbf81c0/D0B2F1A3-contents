---
title: "ADTA 5410 by Bulut, Week 5 Lab"
author: "Abdul Khan"
format: html
editor: visual
---

## General Instructions

1.  You have the option to establish a new folder for this lab assignment and place both this Quarto document and the supplied dataset within it.

2.  The initial code snippet installs specific R packages that could prove valuable in addressing certain questions.

3.  Unless otherwise specified, you have the freedom to select any R package you prefer to address the questions. You are not constrained to utilizing the packages listed in this Quarto template.

4.  Ensure that you include the code responsible for generating each answer, and verify that both your code and its output are visible in your knitted HTML document. You can achieve this by setting **`echo=TRUE`** to print your code chunk in the knitted HTML code.

5.  Once you've completed your work, knit your Quarto document into an HTML document and save it within the folder you established in step 1.

6.  Please submit your assignment by uploading both the knitted HTML document and the QMD file to the specified course portal on Canvas prior to the designated due date and time

7.  Ensure your Quarto Document is saved with the following naming convention: "**LastName_FirstName_Week5.qmd**" (i.e. Doe_Jane_Week5.qmd). Students will lose 2 points for improper file naming.

8.  Please place your code for each task within the specified code section.

9.  Ensure that all non-code written responses are placed within the corresponding Task section where the question content is located.

10. You are allowed to seek assistance from ChatGPT exclusively for assistance in writing your code. However, please be cautious as ChatGPT may occasionally provide inaccurate information when it comes to scripting in specific programming languages.

11. Verbal responses must be articulated in your own words. You cannot use ChatGPT for generating or providing verbal responses. All verbal responses should originate from your own understanding and expression.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(rpart)
library(rsample)
library(caret)
library(mgcv)

knitr::opts_chunk$set(echo = TRUE)



```

## Week 5 Assignment

## Business Problem

For this week's homework, we'll be exploring the 2004 North Carolina birth records. Our focus will be on examining the connection between the behaviors and routines of pregnant mothers and the outcomes of their childbirth. Please note, the dataset we'll be using is a randomly selected subset of the original dataset.

**Attributes:**

-   **Predictors**

    -   **fage**: father's age in years.

    -   **mage**: mother's age in years.

    -   **mature**: maturity status of mother.

    -   **weeks**: length of pregnancy in weeks.

    -   **premie**: whether the birth was classified as premature (premie) or full-term.

    -   **visits**: number of hospital visits during pregnancy.

    -   **marital**: whether mother is married or not married at birth.

    -   **gained**: weight gained by mother during pregnancy in pounds.

    -   **gender**: gender of the baby, female or male.

    -   **habit**: status of the mother as a nonsmoker or a smoker.

    -   **whitemom**: whether mother is white or not white.

**Outcome Variable:**

-   **weight**: weight of the baby at birth in pounds. (Regression problem)

#### Do not change anything in this r chunk. Just run the code chunk and move to the next one

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Run this code chunk without altering it
# clear the session
rm(list=ls())

# Data is stored in a csv file, the first row contains the variable names. 
# we call our data mydata
mydata<-read.csv ("Data_RLab5.csv", header=TRUE)

# remove lowbirthweight
mydata<-mydata%>%
  select(-lowbirthweight)




```

## Task 1: Data Preparation

::: {.callout-important appearance="simple"}
## Task 1

1.  **Data Structure Check**:

    -   Examine the variable descriptions and the overall structure of the dataset in **`mydata`**.

    -   Ensure that each variable is correctly coded in the R object. Specifically, numeric variables should be in numeric format, and factor variables should be coded as factors.

2.  **Handling Missing Values**:

    -   Identify and replace missing values in your dataset.

        -   For numeric variables, fill missing values with the median of that variable.

        -   For categorical variables, use the most frequent category (mode) to replace missing values.

3.  **Correlation Analysis and Visualization**:

    -   Determine the variable that has the highest correlation (in absolute value) with your chosen target variable.

    -   Create a scatter plot to visually represent the relationship between these two variables.

    -   Provide a brief commentary on the scatter plot. Discuss any notable patterns, trends, or insights you observe.

    -   **Insert your written response in here:**
:::

## Your code for Task 1

```{r, echo=TRUE}
# Please provide your code for Task 1 in this code chunk
str(mydata)
head(mydata)


missing_values <- colSums(is.na(mydata))

for (col in names(mydata)) {
  if (is.numeric(mydata[[col]])) {
    mydata[[col]][is.na(mydata[[col]])] <- median(mydata[[col]], na.rm = TRUE)
  } else {
    mode_val <- names(sort(table(mydata[[col]]), decreasing = TRUE))[1]
    mydata[[col]][is.na(mydata[[col]])] <- mode_val
  }
}


numeric_vars <- sapply(mydata, is.numeric)
correlations <- cor(mydata[, numeric_vars])

target_corr <- correlations[,"weight"]
max_corr_var <- names(target_corr[which.max(abs(target_corr))])

library(ggplot2)

# Scatter plot
ggplot(mydata, aes(x = mydata[[max_corr_var]], y = weight)) +
  geom_point() +
  labs(title = paste("Scatter Plot", max_corr_var, "vs. Weight"),
       x = max_corr_var,
       y = "Weight")


#The scatter plot illustrates the connection between the variable 'gained'—indicating the mother's weight gain during pregnancy—and the target variable 'weight', which is the baby's birth weight. This relationship is the most correlated in the dataset.

#Key Points:

#Linear Correlation: The plot demonstrates a notably strong linear correlation between the mother's weight gain ('gained') and the baby's birth weight ('weight'). A higher weight gain by the mother generally corresponds to an increased birth weight of the baby.

#Positive Trend: There's a positive trend observable in the plot, signifying a direct relationship where more weight gain during pregnancy relates to a heavier birth weight. This supports the usual belief linking maternal weight gain to the baby's birth weight.

#Presence of Outliers: Some points on the plot stray from the primary trend, reflecting variations in the relationship. These could result from individual health differences, genetic influences, or personal lifestyle factors.

#Indication of a Linear Model: The scatter plot suggests a straight-line relation, indicative of a linear connection. Nevertheless, it's crucial to recognize that while the trend appears linear, the actual relationship might not be entirely straight. Exploring different models might be beneficial to account for possible non-linear aspects.

#To sum up, the scatter plot sheds light on how the weight gained during pregnancy impacts the baby's birth weight. Further examination, like applying regression analysis, can offer a more detailed and accurate understanding of this relationship.

```

## Task 2: Data Splitting

------------------------------------------------------------------------

::: {.callout-important appearance="simple"}
## Task 2

-   Prior to starting our analysis, we will divide our dataset into two parts: a training set and a test set. For this lab assignment, you'll need to use the **`initial_split`** function from the **`rsample`** package in R to partition the data. Please ensure to use **`set.seed(123456)`** for reproducibility. Allocate 70% of the data to the training set and go with the default options in initial_split function. Conduct stratified sampling by using `strata="weight"`.

-   Name your training set **`train_data`** and your test set **`test_data`**. This division will be crucial for our analysis, allowing us to train our models effectively and test their performance.
:::

## Your code for Task 2

Split the data into a training set (70%) and a test set (30%)

```{r, echo=TRUE}
# Please provide your code for Task 2 in this code chunk
set.seed(123456)

split_data <- initial_split(mydata, prop = 0.7, strata = "weight")

# Create training and test sets
train_data <- training(split_data)
test_data <- testing(split_data)

```

## Task 3:

::: {.callout-important appearance="simple"}
## Task 3

-   In this task, you will be using the **`train_data`** dataset to run a linear regression that takes `weight` as the dependent variable and all the other columns as the predictor.

    -   You will use the **`lm()`** function to estimate your linear model and name it as **`linearmodel`**.

    -   Use the **`predict()`** function to predict the `weight` variable in the **`test_data`** dataset using **`linearmodel`**.

    -   Store the resulting predictions in a new object called **`predicted_weights_ols`**.

    -   Calculate the mean squared prediction error in the **`test_data`** dataset by comparing the predicted `weight` values with the actual `weight` values. Store the resulting value in an object called **`MSPE_linear`**.

-   **Need Written Response:** Print the value of **`MSPE_linear`** to the console using the **`print()`** function
:::

## Your code for Task 3

```{r, echo=TRUE}
linearmodel <- lm(weight ~ ., data = train_data)

predicted_weights_ols <- predict(linearmodel, newdata = test_data)

MSPE_linear <- mean((predicted_weights_ols - test_data$weight)^2)


print(MSPE_linear)


```

## Task 4:

::: {.callout-important appearance="simple"}
## Task 4

-   Use the `gam` function in the **`mgcv`** package to complete the same task. In other words, fit a Generalized additive model (GAM) on the `train_data` using the **`gam()`** function. Use the **`s()`** function for each **suitable** predictor. Save your R object as `gam_model.` If the `gam` output indicates that a variable should be added linearly to the model, then make the necessary changes in `gam_model` and explain your reasoning. As for the parameter tuning, let the package automatically selects the optimal lambda by using the method = "REML".
-   Print out smoothing parameter from `gam_model.`
-   Use the **`predict()`** function to predict the `weight` variable in the **`test_data`** dataset using **`gam_model`**. Store the resulting predictions in a new object called **`predicted_weights_gam`**.
-   Calculate the mean squared prediction error in the **`test_data`** dataset by comparing the predicted 'weight' values with the actual `weight` values. Store the resulting value in an object called **`MSPE_gam`**.

Print the value of **`MSPE_gam`** to the console using the **`print()`** function.
:::

## Your code for Task 4

```{r, echo=TRUE}
# Please provide your code for Task 4 in this code chunk

library(mgcv)

gam_model <- gam(weight ~ s(fage) + s(mage) + s(weeks) + s(visits) + s(gained), data = train_data, method = "REML")

summary(gam_model)$s.table


predicted_weights_gam <- predict(gam_model, newdata = test_data)

MSPE_gam <- mean((predicted_weights_gam - test_data$weight)^2)

print(MSPE_gam)









```

------------------------------------------------------------------------

## TASK 5:

::: {.callout-important appearance="simple"}
## Task 5

-   Evaluate the effectiveness of the linear regression model (**`linearmodel`**) and the generalized additive model (**`gam_model`**) by comparing their Mean Squared Prediction Errors (MSPE). Utilize the values **`MSPE_linear`** and **`MSPE_gam`**, which were derived in previous tasks, to assess which model more accurately predicts the 'weight' variable in the **`test_data`** dataset. The model with the lower MSPE value will be considered as having superior predictive performance for this specific variable.
-   **Insert your written response in here:**
:::

## Your code for Task 5

```{r, echo=TRUE}
# Please provide your code for Task 5 in this code chunk

MSPE_linear <- mean((predicted_weights_ols - test_data$weight)^2)

MSPE_gam <- mean((predicted_weights_gam - test_data$weight)^2)

cat("Linear Regression Model MSPE:", MSPE_linear, "\n")
cat("Generalized Additive Model MSPE:", MSPE_gam, "\n")


if (MSPE_linear < MSPE_gam) {
  cat("Conclusion: Linear Regression Model better performing based on MSPE.\n")
} else if (MSPE_gam < MSPE_linear) {
  cat("Conclusion: Generalized Additive Model better performing based on MSPE.\n")
} else {
  cat("Conclusion: Both models performance are equal based on MSPE.\n")
}


#The Mean Squared Prediction Errors (MSPE) were assessed for both the linear regression model (referred to as linearmodel) and the generalized additive model (referred to as gam_model), utilizing the test_data dataset.

#Calculated MSPE Values:

#MSPE for Linear Model: 1.133044
#MSPE for GAM: 1.159198
#Analysis:

#The linear regression model exhibits a lower MSPE in comparison to the generalized additive model. To be precise, the MSPE for the linear model is 1.133044, whereas for the GAM it is 1.159198.

#Conclusion:

#Given its lower MSPE, the linear regression model (linearmodel) shows better prediction accuracy for the 'weight' variable within the test_data dataset. Hence, based on the MSPE metric, the linear model is the more suitable choice in this particular scenario.

#However, it is important to remember that evaluating models typically involves multiple criteria, and the selection of the most appropriate model may vary based on the specific objectives and the nature of the data involved.






```
